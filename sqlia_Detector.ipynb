{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgEDBTwglwFP",
        "outputId": "68d7d1ee-5705-43ce-8699-9830cffd05fb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.8/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.8/dist-packages (from fasttext) (2.10.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fasttext) (1.21.6)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from fasttext) (57.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oensVieVll6R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import fasttext\n",
        "import re \n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/dataset.csv')"
      ],
      "metadata": {
        "id": "iIfmVJlJm8TV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenization(query):\n",
        "    tokens=query.upper()\n",
        "    if \"WHERE\" in tokens:\n",
        "        tokens=tokens.split(\"WHERE\",1)\n",
        "        tokens=tokens[1]\n",
        "    Dict = { '!=': 'NEQ', '<>': 'NEQ', '&&': 'AND', '||': 'OR', '/*': ' CMTST ',\n",
        "            '*/': 'CMTEND',\n",
        "            '~': 'TLDE', '!': 'EXCLM', '@': 'ATR', '#': 'HASH', '$': 'DLLR', '%': 'PRCNT',\n",
        "            '^': 'XOR', '&': 'BITAND','|': 'BITOR', '*': 'STAR', '--': 'CMNT', '-': 'MINUS',\n",
        "            '+': 'PLUS', '=': 'EQ', '/': 'SLSH', '?': 'QSTN','.': 'DOT',\n",
        "            ',': 'CMMA', '>': 'GT', '<': 'LT', '\\'': 'SQUT', '\"': 'DQUT', ';': 'SMCLN', \n",
        "            ':': 'CLN', '\\\\': 'BSLSH',\n",
        "            ']': 'RSQBR', '[': 'LSQBR', '}': 'RCBR', '{': 'LCBR', ')': 'RPRN', '(': 'LPRN'}\n",
        "    i=0 #counter\n",
        "    while i < len(tokens):\n",
        "        if tokens[i] in Dict: #if token is in dict\n",
        "            if i + 1 < len(tokens) and (tokens[i] + tokens[i + 1]) in Dict: #if two things after each other replace such as ||\n",
        "                tokens=tokens.replace((tokens[i] + tokens[i + 1]),\" \"+Dict[(tokens[i] + tokens[i + 1])]+\" \")\n",
        "            else:\n",
        "                tokens=tokens.replace(tokens[i], \" \"+Dict[tokens[i]]+\" \")# if only 1 replace it\n",
        "           \n",
        "        i = i + 1 #increment counter\n",
        "    tokens =re.sub(r\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})\",\" LNK \",tokens)\n",
        "    tokens =re.sub(r\"((?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?\\.){3}(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)))\",\" IPADDR \",tokens)\n",
        "    tokens =re.sub(r\"\\d+\",\" INT \",tokens)\n",
        "    tokens =re.sub(r\"([A-Fa-f0-9]{2,})\",\" HEX \",tokens)\n",
        "    tokens =re.sub(r\"^\\d*[.,]?\\d*$\",\" DEC \",tokens)\n",
        "    tokens =re.sub(r\"\\b[a-zA-Z]\\b\",\" CHR \",tokens)\n",
        "       \n",
        "    return \"\".join(tokens) # convert it to string again"
      ],
      "metadata": {
        "id": "ozCpuOcftVVY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[:, 1] = df.iloc[:, 1].apply(lambda x: tokenization(str(x))) "
      ],
      "metadata": {
        "id": "iNqAs-out4kj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, test_size=0.2)"
      ],
      "metadata": {
        "id": "j885289hzgMc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[['Label', 'Query']].to_csv('train.txt', \n",
        "                                          index = False, \n",
        "                                          sep = ' ',\n",
        "                                          header = None, \n",
        "                                          quoting = csv.QUOTE_NONE, \n",
        "                                          quotechar = \"\", \n",
        "                                          escapechar = \" \")\n",
        "\n",
        "test[['Label', 'Query']].to_csv('test.txt', \n",
        "                                     index = False, \n",
        "                                     sep = ' ',\n",
        "                                     header = None, \n",
        "                                     quoting = csv.QUOTE_NONE, \n",
        "                                     quotechar = \"\", \n",
        "                                     escapechar = \" \")"
      ],
      "metadata": {
        "id": "-vazx6BF1uZf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = fasttext.train_supervised('train.txt', lr=0.1)\n"
      ],
      "metadata": {
        "id": "CzqcfKPo0CJ4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total, precision, recall = model.test('test.txt') #test the model\n",
        "Fmeasure= 2 * ((precision*recall)/(precision + recall)) #calc f-measure\n",
        "print(str(Fmeasure * 100) + \"%\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoEs6pxC0GE8",
        "outputId": "49a42b60-3f72-4974-bb73-37039106c755"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98.64864864864865%\n"
          ]
        }
      ]
    }
  ]
}